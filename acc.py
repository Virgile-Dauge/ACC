import marimo

__generated_with = "0.14.16"
app = marimo.App(width="medium")

with app.setup:
    import marimo as mo
    import pandas as pd
    import numpy as np
    from pathlib import Path
    from typing import Optional
    import datetime

    from electriflux.simple_reader import process_flux, iterative_process_flux


@app.cell(hide_code=True)
def introduction():
    mo.md(
        r"""
    # üìä Analyse des Donn√©es d'Autoconsommation Collective (ACC)

    Bienvenue dans l'outil d'analyse des donn√©es ACC ! Cette application vous permet d'analyser les donn√©es de facturation et de flux √©lectriques pour r√©gulariser l'autoconsommation collective.

    ## üéØ Objectifs de l'analyse

    - **Traitement des donn√©es R15** : Analyse des flux d'√©nergie, auto et alloconso
    - **Analyse du journal des ventes** : Suivi des tarifs et p√©riodes de facturation  
    - **Identification des changements tarifaires** : D√©tection automatique des variations de prix
    - **P√©riode de r√©gularisation** : Focus sur une p√©riode sp√©cifique d'analyse

    ## üìã Workflow de l'analyse

    1. **Configuration** : Import des biblioth√®ques et fonctions utilitaires
    2. **Donn√©es R15** : Chargement et traitement des fichiers de flux √©lectriques
    3. **Journal des ventes** : Import et analyse des donn√©es de facturation
    4. **Analyse des prix** : Identification des p√©riodes tarifaires et changements

    Suivez les √©tapes ci-dessous pour r√©aliser votre analyse compl√®te.
    """
    )
    return


@app.cell(hide_code=True)
def configuration_section():
    mo.md(
        r"""
    ## ‚öôÔ∏è Configuration et Imports

    Cette section configure l'environnement d'analyse avec tous les outils n√©cessaires :

    ### üìö Biblioth√®ques import√©es
    - **Marimo** : Framework interactif pour les notebooks Python
    - **Pandas & Numpy** : Manipulation et analyse de donn√©es  
    - **Pandera** : Validation des sch√©mas de donn√©es
    - **Electriflux** : Traitement sp√©cialis√© des fichiers de flux √©lectriques

    ### üîß Fonctions utilitaires
    - Mod√®les de validation Pandera pour garantir la qualit√© des donn√©es
    - Algorithme d'identification automatique des p√©riodes de prix
    - Gestion robuste des erreurs et types de donn√©es

    La configuration est maintenant pr√™te pour le traitement de vos donn√©es ACC.
    """
    )
    return


@app.function(hide_code=True)
def identify_price_periods(df: pd.DataFrame) -> pd.DataFrame:
    """
    Identifie les p√©riodes de prix distinctes pour chaque combinaison CONTRAT-CODE_ARTICLE.

    Cette fonction analyse les changements de prix unitaire HT (PUHT) dans le temps pour
    chaque combinaison contrat-article et cr√©e des p√©riodes tarifaires coh√©rentes. Elle
    utilise des op√©rations vectoris√©es pandas pour une performance optimale.

    Algorithme :
    1. Tri chronologique des donn√©es par CONTRAT, CODE_ARTICLE, DATEFACT
    2. Groupement par combinaison CONTRAT-CODE_ARTICLE
    3. D√©tection des changements de prix avec pandas.shift(1)
    4. Identification des points de rupture tarifaire
    5. Calcul des dates de d√©but/fin et dur√©es pour chaque p√©riode

    Args:
        df (pd.DataFrame): DataFrame contenant les colonnes :
            - CONTRAT (str) : Identifiant unique du contrat
            - CODE_ARTICLE (str) : Code de l'article factur√©
            - PUHT (float) : Prix unitaire hors taxe
            - DATEFACT (pd.Timestamp) : Date de facturation

    Returns:
        pd.DataFrame: DataFrame contenant les p√©riodes de prix avec :
            - CONTRAT (str) : Identifiant du contrat
            - CODE_ARTICLE (str) : Code de l'article
            - PUHT (float) : Prix unitaire de la p√©riode
            - date_debut (pd.Timestamp) : Date de d√©but de la p√©riode
            - date_fin (pd.Timestamp) : Date de fin de la p√©riode
            - duree_jours (int) : Dur√©e de la p√©riode en jours (‚â• 1)

    Examples:
        >>> # Donn√©es d'entr√©e avec changement de prix
        >>> data = pd.DataFrame({
        ...     'CONTRAT': ['C001', 'C001', 'C001'],
        ...     'CODE_ARTICLE': ['ABONNEMENT', 'ABONNEMENT', 'ABONNEMENT'], 
        ...     'PUHT': [12.0, 12.0, 15.0],
        ...     'DATEFACT': pd.to_datetime(['2023-01-01', '2023-02-01', '2023-03-01'])
        ... })
        >>> periods = identify_price_periods(data)
        >>> len(periods)
        2
        >>> periods.iloc[0]['duree_jours']  # Premi√®re p√©riode
        59
        >>> periods.iloc[1]['PUHT']  # Nouveau prix
        15.0

        >>> # Donn√©es vides
        >>> empty_df = pd.DataFrame(columns=['CONTRAT', 'CODE_ARTICLE', 'PUHT', 'DATEFACT'])
        >>> result = identify_price_periods(empty_df)
        >>> result.empty
        True

    Note:
        - Les p√©riodes sont calcul√©es de mani√®re inclusive (date_fin incluse)
        - Pour la derni√®re p√©riode d'un groupe, date_fin = derni√®re DATEFACT du groupe
        - Les donn√©es sont automatiquement tri√©es par ordre chronologique
        - La fonction g√®re les DataFrames vides en retournant une structure vide valide
    """
    if df.empty:
        # Retourner un DataFrame vide avec la structure attendue
        return pd.DataFrame(columns=['CONTRAT', 'CODE_ARTICLE', 'PUHT', 'date_debut', 'date_fin', 'duree_jours'])

    # Trier par contrat, article et date pour avoir une s√©quence temporelle coh√©rente
    df_sorted = df.sort_values(['CONTRAT', 'CODE_ARTICLE', 'DATEFACT']).copy()

    # Grouper par contrat et article
    grouped = df_sorted.groupby(['CONTRAT', 'CODE_ARTICLE'])

    periods_list = []

    for (contrat, article), group in grouped:
        # D√©tecter les changements de prix avec shift() - op√©ration vectoris√©e
        price_changes = group['PUHT'] != group['PUHT'].shift(1)
        # Le premier √©l√©ment est toujours un "changement"
        price_changes.iloc[0] = True

        # Identifier les indices o√π il y a changement de prix
        change_indices = group[price_changes].index

        # Cr√©er les p√©riodes de prix
        for i, start_idx in enumerate(change_indices):
            # Date de d√©but de la p√©riode
            date_debut = group.loc[start_idx, 'DATEFACT']
            # Prix de la p√©riode
            puht = group.loc[start_idx, 'PUHT']

            # Date de fin : derni√®re date du groupe ou d√©but de la p√©riode suivante - 1 jour
            if i < len(change_indices) - 1:
                # Il y a une p√©riode suivante
                next_start_idx = change_indices[i + 1]
                date_fin = group.loc[next_start_idx, 'DATEFACT'] - pd.Timedelta(days=1)
            else:
                # Derni√®re p√©riode : prendre la derni√®re date du groupe
                date_fin = group['DATEFACT'].iloc[-1]

            # Calculer la dur√©e en jours
            duree_jours = (date_fin - date_debut).days + 1

            periods_list.append({
                'CONTRAT': contrat,
                'CODE_ARTICLE': article, 
                'PUHT': puht,
                'date_debut': date_debut,
                'date_fin': date_fin,
                'duree_jours': duree_jours
            })

    # Cr√©er le DataFrame r√©sultat
    result_df = pd.DataFrame(periods_list)

    if result_df.empty:
        # Retourner un DataFrame vide avec la structure attendue
        return pd.DataFrame(columns=['CONTRAT', 'CODE_ARTICLE', 'PUHT', 'date_debut', 'date_fin', 'duree_jours'])

    return result_df


@app.cell(hide_code=True)
def donnees_r15_section():
    mo.md(
        r"""
    ## üìÅ Chargement des Donn√©es R15

    Les donn√©es R15 contiennent les mesures de flux √©lectriques pour l'autoconsommation collective. Ces fichiers ZIP contiennent les relev√©s d√©taill√©s de production et consommation.

    ### üîç Que contiennent les donn√©es R15 ?
    - **Mesures √©nerg√©tiques** : √ânergie active (EA) et r√©active par p√©riode
    - **Horodatage** : Date et heure des relev√©s
    - **Identification ACC** : Flag d'autoconsommation collective
    - **Donn√©es de comptage** : Relev√©s d√©taill√©s par point de mesure

    ### ‚ö° Traitement automatique
    - Conversion des colonnes EA en format num√©rique
    - Normalisation des dates en UTC  
    - Validation de la coh√©rence des donn√©es

    **üëá S√©lectionnez le dossier contenant vos fichiers ZIP R15 :**
    """
    )
    return


@app.cell(hide_code=True)
def _():
    folder_picker = mo.ui.file_browser(
        initial_path=Path('~/data/ACC').expanduser(),
        selection_mode="directory", 
        label="S√©lectionnez le dossier contenant les zip R15 √† traiter"
    )
    return (folder_picker,)


@app.cell(hide_code=True)
def _(folder_picker):
    folder_picker
    return


@app.cell
def _(folder_picker):
    mo.stop(not folder_picker.value, mo.md("‚ö†Ô∏è **Veuillez s√©lectionner un dossier contenant les fichiers R15 √† traiter**"))

    r15 = process_flux('R15_ACC', folder_picker.value[0].path)

    # Convertir toutes les colonnes commen√ßant par 'EA' en num√©rique
    ea_columns = [col for col in r15.columns if col.startswith('EA')]
    for col in ea_columns:
        r15[col] = pd.to_numeric(r15[col], errors='coerce')

    # Convertir Date_Releve en format date
    if 'Date_Releve' in r15.columns:
        r15['Date_Releve'] = pd.to_datetime(r15['Date_Releve'], errors='coerce', utc=True)

    return (r15,)


@app.cell(hide_code=True)
def donnees_r15_display():
    mo.md(
        r"""
    ### üìä Aper√ßu des Donn√©es R15 Charg√©es

    Les donn√©es R15 ont √©t√© charg√©es avec succ√®s ! Le tableau ci-dessous pr√©sente un √©chantillon des donn√©es trait√©es :

    **Points cl√©s :**
    - Toutes les colonnes √©nerg√©tiques (EA) ont √©t√© converties en format num√©rique
    - Les dates sont normalis√©es en UTC pour √©viter les probl√®mes de timezone
    - Les donn√©es sont pr√™tes pour l'analyse des flux d'autoconsommation

    **Navigation :** Utilisez les contr√¥les du tableau pour explorer les diff√©rentes colonnes et p√©riodes.
    """
    )
    return


@app.cell
def _(r15):
    r15
    return


@app.cell(hide_code=True)
def debut_acc_info():
    mo.md(
        r"""
    ### üìÖ Identification du D√©but de l'Autoconsommation Collective

    Le syst√®me identifie automatiquement la date de d√©but de l'autoconsommation collective en analysant les donn√©es R15.

    **Comment √ßa fonctionne :**
    - Recherche de la premi√®re occurrence du flag `Autoconsommation_Collective = '0'`
    - Cette date marque le commencement officiel de l'ACC
    - Toutes les analyses ult√©rieures utiliseront cette date comme r√©f√©rence

    **Date de d√©but ACC identifi√©e :**
    """
    )
    return


@app.cell
def _(r15):
    debut_acc = r15[r15['Autoconsommation_Collective'] == '0']['Date_Releve'].min()
    debut_acc
    return (debut_acc,)


@app.cell(hide_code=True)
def periode_regularisation_section():
    mo.md(
        r"""
    ## üó∫Ô∏è S√©lection de la P√©riode de R√©gularisation

    La p√©riode de r√©gularisation d√©finit l'intervalle temporel pour votre analyse. Cette s√©lection d√©termine :

    ### üìä Impact sur l'analyse
    - **Filtrage des donn√©es R15** : Seules les donn√©es entre le d√©but ACC et cette date seront analys√©es
    - **Scope du journal des ventes** : Les facturations hors p√©riode seront exclues
    - **Calculs tarifaires** : Les analyses de prix se concentreront sur cette p√©riode

    ### üéØ Recommandations
    - Choisissez le dernier jour du mois pour une analyse mensuelle compl√®te
    - Alignez avec vos cycles de facturation habituels
    - Consid√©rez les p√©riodes de changements tarifaires connus

    **üëá S√©lectionnez votre mois de r√©gularisation :**
    """
    )
    return


@app.cell(hide_code=True)
def _():
    # Date par d√©faut : premier jour du mois courant
    current_date = datetime.date.today()
    default_date = current_date.replace(day=1)

    date_regularisation_picker = mo.ui.date(
        value=default_date,
        label="S√©lectionnez le mois de r√©gularisation",
        start=datetime.date(2022, 1, 1),  # Date minimum
        stop=current_date  # Date maximum (aujourd'hui)
    )

    return (date_regularisation_picker,)


@app.cell(hide_code=True)
def _(date_regularisation_picker):
    date_regularisation_picker
    return


@app.cell
def _(date_regularisation_picker, debut_acc, r15):

    # Convertir la date de r√©gularisation en datetime avec timezone UTC (coh√©rent avec les autres dates)
    date_regularisation = pd.to_datetime(date_regularisation_picker.value, utc=True)

    # Filtrer les donn√©es R15
    r15_filtered = r15[
        (r15['Date_Releve'] >= debut_acc) & 
        (r15['Date_Releve'] <= date_regularisation) &
        (r15['Autoconsommation_Collective'] == '0')
    ].copy()

    # Afficher un r√©sum√© du filtrage
    print(f"P√©riode filtr√©e : de {debut_acc.date()} √† {date_regularisation.date()}")
    print(f"Nombre de lignes apr√®s filtrage : {len(r15_filtered)} (sur {len(r15)} lignes totales)")

    return date_regularisation, r15_filtered


@app.cell
def _(r15_filtered):
    r15_filtered
    return


@app.cell(hide_code=True)
def journal_ventes_section():
    mo.md(
        r"""
    ## üßæ Chargement du Journal des Ventes D√©taill√©s

    Le journal des ventes contient l'historique complet des facturations pour vos contrats ACC. Ces donn√©es sont essentielles pour :

    ### üí∞ Contenu du journal des ventes
    - **Informations contractuelles** : Identifiants contrats et clients
    - **D√©tail des articles** : Types de prestations factur√©es (abonnement, consommation...)
    - **Tarification** : Prix unitaires HT (PUHT) par p√©riode
    - **Chronologie** : Dates de facturation pour l'analyse temporelle

    ### üîÑ Filtrage automatique
    Les donn√©es seront automatiquement filtr√©es selon ces crit√®res :
    - **P√©riode temporelle** : d√©but ACC ‚Üí date de r√©gularisation
    - **Articles CONSO uniquement** : seuls les articles commen√ßant par "CONSO" seront analys√©s

    Les articles d'abonnement et autres prestations seront exclus de l'analyse des changements de prix.

    **üëá S√©lectionnez votre fichier Excel du journal des ventes :**
    """
    )
    return


@app.cell(hide_code=True)
def _():
    journal_picker = mo.ui.file_browser(
        initial_path=Path('~/data/ACC/').expanduser(),
        selection_mode="file",
        restrict_navigation=False,
        label="S√©lectionnez le fichier Journal des ventes d√©taill√©s (.xlsx)",
        filetypes=[".xlsx", ".xls"]
    )
    return (journal_picker,)


@app.cell(hide_code=True)
def _(journal_picker):
    journal_picker
    return


@app.cell
def _(date_regularisation, debut_acc, journal_picker):
    mo.stop(not journal_picker.value, mo.md("‚ö†Ô∏è **Veuillez s√©lectionner le fichier Journal des ventes d√©taill√©s**"))

    # Charger le fichier Excel s√©lectionn√©
    journal_ventes = pd.read_excel(journal_picker.value[0].path)

    # Convertir DATEFACT en format date avec UTC (m√™me approche que R15)
    if 'DATEFACT' in journal_ventes.columns:
        journal_ventes['DATEFACT'] = pd.to_datetime(journal_ventes['DATEFACT'], errors='coerce', utc=True)

    # Validation simple des donn√©es
    validation_messages = []

    # V√©rifier les colonnes essentielles
    required_cols = ['CONTRAT', 'CODE_ARTICLE', 'PUHT', 'DATEFACT']
    missing_cols = [col for col in required_cols if col not in journal_ventes.columns]
    if missing_cols:
        validation_messages.append(f"‚ö†Ô∏è Colonnes manquantes : {missing_cols}")

    # V√©rifier les types et convertir
    try:
        journal_ventes['PUHT'] = pd.to_numeric(journal_ventes['PUHT'], errors='coerce')
        invalid_puht = journal_ventes['PUHT'].isnull().sum()
        if invalid_puht > 0:
            validation_messages.append(f"‚ö†Ô∏è {invalid_puht} valeurs PUHT invalides converties en NaN")
    except Exception:
        validation_messages.append("‚ö†Ô∏è Probl√®me de conversion PUHT")

    # Message final de validation
    if not validation_messages:
        validation_message = "‚úÖ **Validation r√©ussie** : Donn√©es pr√™tes pour l'analyse"
    else:
        validation_message = "üîÑ **Validation avec avertissements** :\n" + "\n".join(validation_messages)

    journal_ventes_validated = journal_ventes

    # Filtrer les donn√©es du journal entre debut_acc et date_regularisation
    journal_ventes_filtered = journal_ventes_validated[
        (journal_ventes_validated['DATEFACT'] >= debut_acc) & 
        (journal_ventes_validated['DATEFACT'] <= date_regularisation)
    ].copy()

    # Filtrage des articles CONSO uniquement
    journal_ventes_conso = journal_ventes_filtered[
        journal_ventes_filtered['CODE_ARTICLE'].str.startswith('CONSO', na=False)
    ].copy()

    # Messages informatifs sur le filtrage
    nb_lignes_avant_filtrage_conso = len(journal_ventes_filtered)
    nb_lignes_apres_filtrage_conso = len(journal_ventes_conso)
    nb_lignes_filtrees_conso = nb_lignes_avant_filtrage_conso - nb_lignes_apres_filtrage_conso

    # Articles CONSO uniques identifi√©s
    articles_conso_uniques = sorted(journal_ventes_conso['CODE_ARTICLE'].unique()) if not journal_ventes_conso.empty else []

    mo.md(f"""‚úÖ **Fichier charg√©:** {journal_picker.value[0].name}

    {validation_message}

    **P√©riode filtr√©e:** de {debut_acc.date()} √† {date_regularisation.date()}

    **Nombre de lignes apr√®s filtrage temporel:** {nb_lignes_avant_filtrage_conso} (sur {len(journal_ventes_validated)} lignes totales)

    üîç **Filtrage articles CONSO appliqu√©:**

    - **{nb_lignes_apres_filtrage_conso}** lignes conserv√©es (articles CONSO)
    - **{nb_lignes_filtrees_conso}** lignes filtr√©es (articles non-CONSO)
    - **Articles CONSO identifi√©s:** {', '.join(articles_conso_uniques) if articles_conso_uniques else 'Aucun'}

    ‚úÖ **Seuls les articles de consommation (CONSO_*) seront analys√©s pour les changements de prix**""")

    journal_ventes = journal_ventes_conso
    return (journal_ventes,)


@app.cell(hide_code=True)
def journal_ventes_display():
    mo.md(
        r"""
    ### üìã Aper√ßu du Journal des Ventes

    Donn√©es du journal des ventes charg√©es et filtr√©es sur votre p√©riode d'analyse.

    **Validation et filtrage des donn√©es :**

    - Dates de facturation converties en UTC
    - Filtrage appliqu√© sur la p√©riode de r√©gularisation
    - **Filtrage CONSO** : seuls les articles commen√ßant par "CONSO" sont conserv√©s
    - Structure des donn√©es v√©rifi√©e

    **Colonnes importantes :**

    - **CONTRAT** : Identifiant unique du contrat
    - **CODE_ARTICLE** : Type de prestation CONSO (CONSO_BASE, CONSO_HP, CONSO_HC...)
    - **PUHT** : Prix unitaire hors taxe (utilis√© pour d√©tecter les changements)
    - **DATEFACT** : Date de facturation
    """
    )
    return


@app.cell
def _(journal_ventes):
    journal_ventes
    return


@app.cell(hide_code=True)
def groupement_donnees_section():
    mo.md(
        r"""
    ## üìä Groupement et Agr√©gation des Donn√©es

    Cette √©tape consolide les donn√©es de facturation pour simplifier l'analyse. Le groupement s'effectue par :

    ### üîÑ Logique de groupement
    - **CONTRAT** : Regroupement par contrat client
    - **P√âRIODE** : Consolidation par p√©riode de facturation  
    - **CODE_ARTICLE** : Agr√©gation par type de prestation
    - **PUHT** : Maintien du prix unitaire pour l'analyse tarifaire

    ### üìà R√®gles d'agr√©gation
    - **Colonnes num√©riques** : Somme des montants factur√©s
    - **PDS_CONTRAT** : Conservation de la premi√®re valeur (r√©f√©rence stable)
    - **Suppression des doublons** : √âlimination des lignes redondantes

    Cette agr√©gation facilite l'identification des changements de prix et l'analyse des p√©riodes tarifaires.
    """
    )
    return


@app.cell
def _(journal_ventes):
    mo.stop(journal_ventes is None, mo.md("‚ö†Ô∏è **En attente du chargement du journal des ventes**"))

    # Grouper et sommer par CONTRAT, P√âRIODE et NOM_ARTICLE
    # Colonnes de groupby
    groupby_cols = ['CONTRAT', 'P√âRIODE', 'CODE_ARTICLE', 'PUHT']

    # Colonnes num√©riques √† sommer (exclure PDS_CONTRAT et les colonnes de groupby)
    _numeric_cols = [col for col in journal_ventes.columns 
                    if journal_ventes[col].dtype in ['int64', 'float64'] 
                    and col not in ['PDS_CONTRAT'] + groupby_cols]

    # Cr√©er le dictionnaire d'agr√©gation
    agg_dict = {col: 'sum' for col in _numeric_cols}
    # Pour PDS_CONTRAT, prendre la premi√®re valeur (devrait √™tre la m√™me pour un contrat)
    if 'PDS_CONTRAT' in journal_ventes.columns:
        agg_dict['PDS_CONTRAT'] = 'first'

    journal_grouped = journal_ventes.groupby(groupby_cols).agg(agg_dict).reset_index()

    mo.md(f"‚úÖ **Donn√©es group√©es:** {len(journal_grouped)} lignes (depuis {len(journal_ventes)} lignes originales)")

    return (journal_grouped,)


@app.cell(hide_code=True)
def journal_grouped_display():
    mo.md(
        r"""
    ### üìä Donn√©es Group√©es et Consolid√©es

    Le journal des ventes a √©t√© agr√©g√© avec succ√®s ! Cette vue consolid√©e pr√©sente :

    **Avantages du groupement :**
    - üéØ **Vue synth√©tique** : Une ligne par combinaison contrat/p√©riode/article
    - üí∞ **Montants agr√©g√©s** : Somme des facturations par groupe
    - üîç **Simplification** : R√©duction du nombre de lignes pour faciliter l'analyse
    - ‚ö° **Performance** : Traitement plus rapide pour les analyses suivantes

    Ces donn√©es group√©es serviront de base pour l'identification des p√©riodes de prix et l'analyse des changements tarifaires.
    """
    )
    return


@app.cell
def _(journal_grouped):
    journal_grouped
    return


@app.cell(hide_code=True)
def analyse_prix_section():
    mo.md(
        r"""
    ## üîç Analyse des P√©riodes de Prix

    Cette section identifie automatiquement les diff√©rentes p√©riodes tarifaires dans vos donn√©es de facturation.

    ### üßÆ Algorithme d'identification
    L'algorithme analyse chaque combinaison CONTRAT-CODE_ARTICLE pour :

    - **D√©tecter les changements** : Variations du prix unitaire HT (PUHT) dans le temps
    - **Cr√©er des p√©riodes** : Segments temporels avec tarification stable
    - **Calculer les dur√©es** : Nombre de jours par p√©riode tarifaire
    - **Valider la coh√©rence** : V√©rification des donn√©es avec Pandera

    ### üìä M√©triques g√©n√©r√©es
    - Nombre total de p√©riodes identifi√©es
    - Articles avec changements de prix
    - Dur√©e moyenne des p√©riodes tarifaires
    - R√©partition par contrat et type d'article

    L'analyse s'effectue sur la p√©riode filtr√©e (d√©but ACC ‚Üí date de r√©gularisation).
    """
    )
    return


@app.cell
def _(journal_ventes):
    mo.stop(journal_ventes is None, mo.md("‚ö†Ô∏è **En attente du chargement du journal des ventes**"))

    # Pr√©parer les donn√©es avec les colonnes requises par le mod√®le Pandera
    journal_for_periods = journal_ventes[['CONTRAT', 'CODE_ARTICLE', 'PUHT', 'DATEFACT']].copy()

    # Identifier les p√©riodes de prix distinctes
    price_periods = identify_price_periods(journal_for_periods)

    # Statistiques r√©sum√©es
    total_contrats = price_periods['CONTRAT'].nunique() if not price_periods.empty else 0
    total_articles = price_periods['CODE_ARTICLE'].nunique() if not price_periods.empty else 0
    total_periods = len(price_periods)

    # Analyse des changements de prix par contrat
    if not price_periods.empty:
        changes_by_contract = (price_periods.groupby(['CONTRAT', 'CODE_ARTICLE'])
                              .size()
                              .reset_index(name='nb_periodes_prix'))
        # Articles avec plus d'une p√©riode de prix (donc des changements)
        articles_with_changes = changes_by_contract[changes_by_contract['nb_periodes_prix'] > 1]
        nb_articles_changes = len(articles_with_changes)
    else:
        changes_by_contract = pd.DataFrame()
        articles_with_changes = pd.DataFrame() 
        nb_articles_changes = 0

    mo.md(f"""## üìä Analyse des P√©riodes de Prix

    **R√©sum√© global:**

    - **{total_contrats}** contrats analys√©s
    - **{total_articles}** articles diff√©rents  
    - **{total_periods}** p√©riodes de prix identifi√©es
    - **{nb_articles_changes}** articles avec changements de prix

    Les p√©riodes de prix ont √©t√© identifi√©es en d√©tectant les changements de PUHT dans la s√©quence chronologique pour chaque combinaison CONTRAT-CODE_ARTICLE.
    """)

    return (price_periods,)


@app.cell(hide_code=True)
def periodes_prix_display():
    mo.md(
        r"""
    ### üó∫Ô∏è P√©riodes de Prix Identifi√©es

    Tableau d√©taill√© de toutes les p√©riodes tarifaires d√©tect√©es dans vos donn√©es.

    **Structure des r√©sultats :**

    - **CONTRAT** : Identifiant du contrat concern√©
    - **CODE_ARTICLE** : Type de prestation tarif√©e
    - **PUHT** : Prix unitaire stable durant la p√©riode
    - **date_debut** : Date de d√©but de la p√©riode (inclusive)
    - **date_fin** : Date de fin de la p√©riode (inclusive)  
    - **duree_jours** : Dur√©e totale en jours

    **Interpr√©tation :**

    - Chaque ligne repr√©sente une p√©riode de prix stable
    - Les dates sont continues entre les p√©riodes d'un m√™me article
    - Un changement de PUHT g√©n√®re une nouvelle p√©riode
    """
    )
    return


@app.cell
def _(price_periods):
    price_periods
    return


@app.cell
def _(price_periods, r15_filtered):
    # Regrouper les donn√©es R15 par p√©riode de prix

    # V√©rifier qu'on a les donn√©es n√©cessaires
    if r15_filtered.empty or price_periods.empty:
        print("‚ö†Ô∏è Donn√©es manquantes pour le regroupement par p√©riode")
        r15_by_period = pd.DataFrame()
    else:
        # Cr√©er une liste pour stocker les r√©sultats
        period_aggregations = []

        # Pour chaque p√©riode de prix identifi√©e
        for _, period in price_periods.iterrows():
            # Filtrer les donn√©es R15 pour cette p√©riode
            mask = (
                (r15_filtered['Date_Releve'] >= period['date_debut']) & 
                (r15_filtered['Date_Releve'] <= period['date_fin'])
            )
            r15_period = r15_filtered[mask]

            if not r15_period.empty:
                # Identifier les colonnes num√©riques (notamment celles commen√ßant par EA)
                numeric_cols = r15_period.select_dtypes(include=['float64', 'int64']).columns.tolist()

                # Calculer les sommes pour les colonnes num√©riques
                aggregation = {col: r15_period[col].sum() for col in numeric_cols}

                # Ajouter les informations de la p√©riode
                aggregation['CONTRAT'] = period['CONTRAT']
                aggregation['CODE_ARTICLE'] = period['CODE_ARTICLE']
                aggregation['PUHT'] = period['PUHT']
                aggregation['date_debut'] = period['date_debut']
                aggregation['date_fin'] = period['date_fin']
                aggregation['duree_jours'] = period['duree_jours']
                aggregation['nb_lignes_r15'] = len(r15_period)

                period_aggregations.append(aggregation)

        # Cr√©er le DataFrame final
        if period_aggregations:
            r15_by_period = pd.DataFrame(period_aggregations)

            # R√©organiser les colonnes pour mettre les infos de p√©riode en premier
            info_cols = ['CONTRAT', 'CODE_ARTICLE', 'PUHT', 'date_debut', 'date_fin', 'duree_jours', 'nb_lignes_r15']
            numeric_cols = [col for col in r15_by_period.columns if col not in info_cols]
            r15_by_period = r15_by_period[info_cols + numeric_cols]

            print(f"‚úÖ Regroupement effectu√© : {len(r15_by_period)} p√©riodes avec donn√©es R15")
            print(f"üìä Colonnes num√©riques agr√©g√©es : {', '.join(numeric_cols[:5])}{'...' if len(numeric_cols) > 5 else ''}")
        else:
            r15_by_period = pd.DataFrame()
            print("‚ö†Ô∏è Aucune correspondance trouv√©e entre les p√©riodes de prix et les donn√©es R15")

    r15_by_period
    return (r15_by_period,)


@app.cell
def _(r15_by_period):
    # Afficher le tableau de regroupement par p√©riode
    r15_by_period
    return


if __name__ == "__main__":
    app.run()
